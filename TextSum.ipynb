{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextSum.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIz9Jj5lI/4X/fBYsG61Lj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalnarnaware/TextSummary/blob/master/TextSum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg-Yo496jdj8",
        "colab_type": "code",
        "outputId": "db5c8d61-fda0-4124-bfd2-f13bf4dc4706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "delP6IYdmS7w",
        "colab_type": "code",
        "outputId": "d345c677-a31e-423e-919a-241b20519076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /gdrive/My Drive/Colab Notebooks/textsummary"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Colab Notebooks/textsummary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w5YU8-9l38Q",
        "colab_type": "code",
        "outputId": "d198b888-13e6-4275-92e6-3d624a506d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import time\n",
        "\n",
        "file_name=input(\"Enter file name:\")\n",
        "file_name=file_name+str('.txt')\n",
        "file=open(file_name,\"r\")\n",
        "t = file.readlines()\n",
        "def listToString(s):  \n",
        "    \n",
        "    # initialize an empty string \n",
        "    str1 = \"\"  \n",
        "    \n",
        "    # traverse in the string   \n",
        "    for ele in s:  \n",
        "        str1 += ele   \n",
        "    \n",
        "    # return string   \n",
        "    return str1  \n",
        "text_str = listToString(t)\n",
        "\n",
        "def _create_frequency_table(text_string) -> dict:\n",
        "    \"\"\"\n",
        "    we create a dictionary for the word frequency table.\n",
        "    For this, we should only use the words that are not part of the stopWords array.\n",
        "    Removing stop words and making frequency table\n",
        "    Stemmer - an algorithm to bring words to its root word.\n",
        "    :rtype: dict\n",
        "    \"\"\"\n",
        "    stopWords = set(stopwords.words(\"english\"))\n",
        "    words = word_tokenize(text_string)\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    freqTable = dict()\n",
        "    for word in words:\n",
        "        word = ps.stem(word)\n",
        "        if word in stopWords:\n",
        "            continue\n",
        "        if word in freqTable:\n",
        "            freqTable[word] += 1\n",
        "        else:\n",
        "            freqTable[word] = 1\n",
        "\n",
        "    return freqTable\n",
        "\n",
        "\n",
        "def _score_sentences(sentences, freqTable) -> dict:\n",
        "    \"\"\"\n",
        "    score a sentence by its words\n",
        "    Basic algorithm: adding the frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
        "    :rtype: dict\n",
        "    \"\"\"\n",
        "\n",
        "    sentenceValue = dict()\n",
        "\n",
        "    for sentence in sentences:\n",
        "        word_count_in_sentence = (len(word_tokenize(sentence)))\n",
        "        word_count_in_sentence_except_stop_words = 0\n",
        "        for wordValue in freqTable:\n",
        "            if wordValue in sentence.lower():\n",
        "                word_count_in_sentence_except_stop_words += 1\n",
        "                if sentence[:10] in sentenceValue:\n",
        "                    sentenceValue[sentence[:10]] += freqTable[wordValue]\n",
        "                else:\n",
        "                    sentenceValue[sentence[:10]] = freqTable[wordValue]\n",
        "\n",
        "        if sentence[:10] in sentenceValue:\n",
        "            sentenceValue[sentence[:10]] = sentenceValue[sentence[:10]] / word_count_in_sentence_except_stop_words\n",
        "\n",
        "        '''\n",
        "        Notice that a potential issue with our score algorithm is that long sentences will have an advantage over short sentences. \n",
        "        To solve this, we're dividing every sentence score by the number of words in the sentence.\n",
        "        \n",
        "        Note that here sentence[:10] is the first 10 character of any sentence, this is to save memory while saving keys of\n",
        "        the dictionary.\n",
        "        '''\n",
        "\n",
        "    return sentenceValue\n",
        "\n",
        "\n",
        "def _find_average_score(sentenceValue) -> int:\n",
        "    \"\"\"\n",
        "    Find the average score from the sentence value dictionary\n",
        "    :rtype: int\n",
        "    \"\"\"\n",
        "    sumValues = 0\n",
        "    for entry in sentenceValue:\n",
        "        sumValues += sentenceValue[entry]\n",
        "\n",
        "    # Average value of a sentence from original text\n",
        "    average = (sumValues / len(sentenceValue))\n",
        "\n",
        "    return average\n",
        "\n",
        "\n",
        "def _generate_summary(sentences, sentenceValue, threshold):\n",
        "    sentence_count = 0\n",
        "    summary = ''\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if sentence[:10] in sentenceValue and sentenceValue[sentence[:10]] >= (threshold):\n",
        "            summary += \" \" + sentence\n",
        "            sentence_count += 1\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "def run_summarization(text):\n",
        "    # 1 Create the word frequency table\n",
        "    freq_table = _create_frequency_table(text)\n",
        "\n",
        "    '''\n",
        "    We already have a sentence tokenizer, so we just need \n",
        "    to run the sent_tokenize() method to create the array of sentences.\n",
        "    '''\n",
        "\n",
        "    # 2 Tokenize the sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # 3 Important Algorithm: score the sentences\n",
        "    sentence_scores = _score_sentences(sentences, freq_table)\n",
        "\n",
        "    # 4 Find the threshold\n",
        "    threshold = _find_average_score(sentence_scores)\n",
        "\n",
        "    # 5 Important Algorithm: Generate the summary\n",
        "    summary = _generate_summary(sentences, sentence_scores, 0.95 * threshold)\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tic=time.time()\n",
        "    result = run_summarization(text_str)\n",
        "    print(result)\n",
        "    toc=time.time()\n",
        "    print(\"Time Taken: \",(toc-tic)*1000,\"sec\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Enter file name:foolcrow\n",
            " Once upon a time there lived a crow. At the root of the same tree, a snake had built its home. Whenever the crow laid eggs, the snake would eat them up. The crow felt helpless. “That evil snake. I must do something. Let me go and talk to him,\" thought the crow. You cannot expect me to go hungry. Eggs are what I eat,\" replied the snake, in a nasty tone. The crow felt angry and she thought, “I must teach that snake a lesson.\" The very next day, the crow was flying over the King’s palace. She saw the Princess wearing an expensive necklace. When the Princess saw the crow flying off with her necklace, she screamed, “Somebody help, the crow has taken my necklace.\" The clever crow thought, “Now is the time to act.\" When the snake heard the noise, it came out of its pit of house. The palace guards saw the snake. “A snake! they shouted. With big sticks, they beat the snake and killed it.\n",
            "Time Taken:  16.702890396118164 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_yKQrbljcRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}